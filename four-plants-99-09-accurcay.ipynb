{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Conv2D\n","import numpy as np\n","from tensorflow.keras.preprocessing import image\n","import time"]},{"cell_type":"markdown","metadata":{},"source":["## Callback Function to stop epoch at 0.99 validation accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('val_accuracy')>0.99):\n","      print(\"\\nReached 99% accuracy so cancelling training!\")\n","      self.model.stop_training = True"]},{"cell_type":"markdown","metadata":{},"source":["## Early Stopping code if the validation loss is not decreasing for a certain period. "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","\n","# Define EarlyStopping callback\n","es = EarlyStopping(\n","    \n","    monitor='val_loss',   # Monitor validation loss\n","    mode= 'min', \n","    patience=5, # Number of epochs with no improvement before stopping\n","    verbose=1,\n","    restore_best_weights=True  # Restore model weights to the best achieved during training\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Data Augmentation and Scaling "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import os\n","import zipfile\n","\n","\n","\n","\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255.,\n","                                    rotation_range = 40,\n","                                    width_shift_range = 0.2,\n","                                    height_shift_range = 0.2,\n","                                    shear_range = 0.2,\n","                                    zoom_range = 0.2,\n","                                    horizontal_flip =True,\n","#                                    rotation_range=20,\n","                                    vertical_flip=True,\n","                                    fill_mode='nearest',                     \n","                                   )\n","\n","# Note that the validation data should not be augmented!\n","test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory('/kaggle/input/four-plants-leaf-disease/Cherry_Strawberry_Peach_Soyabean/Train',\n","                                                    batch_size = 32,\n","                                                    class_mode = 'categorical', \n","                                                    target_size = (120,120))     \n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator =  test_datagen.flow_from_directory( '/kaggle/input/four-plants-leaf-disease/Cherry_Strawberry_Peach_Soyabean/Validation',\n","                                                          batch_size  = 32,\n","                                                          class_mode  = 'categorical', \n","                                                          target_size = (120,120),\n","                                                          shuffle = False \n","                                                    )\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# CNN-SVM Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPool2D, GlobalMaxPooling2D,Dropout\n","\n","\n","\n","model = Sequential()\n","\n","model.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (120,120,3), name=\"L1\")),\n","model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n","model.add(BatchNormalization()),\n","# model.add(Dropout(0.1)),\n","\n","\n","model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu',name=\"L2\")),\n","model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n","model.add(BatchNormalization()),\n","# model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n","\n","model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu',name=\"L3\")),\n","model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n","model.add(BatchNormalization()),\n","\n","\n","model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu',name=\"L4\")),\n","model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n","model.add(BatchNormalization()),\n","# model.add(Dropout(0.1)),\n","\n","\n","# model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n","# model.add(Conv2D(512 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu',name=\"L5\")),\n","# model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n","# model.add(Conv2D(1028 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu',name=\"L6\")),\n","# model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n","\n","\n","\n","model.add(Flatten()),\n","model.add(BatchNormalization()),\n","model.add(Dropout(0.2)),\n","model.add(Dense(units = 32, activation = 'relu')),\n","\n","\n","\n","model.add(Dense(10, kernel_regularizer= tf.keras.regularizers.l2(0.01),activation = 'softmax'))\n","\n","\n","model.summary()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["start = time.time()\n","\n","# Compiling the CNN  # Set the training parameters\n","# model.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n","#optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n","\n","model.compile(optimizer = optimizer ,loss = 'squared_hinge', metrics = ['accuracy'])\n","\n","\n","# Training the CNN on the Training set and evaluating it on the Test set\n","callbacks = myCallback()\n","history = model.fit( train_generator, \n","                  validation_data = validation_generator, \n","                  epochs = 350,  \n","                  callbacks=[callbacks]  # use 'es' for early stopping\n","#                   steps_per_epoch=62,\n","                  #validation_steps=6\n","                 )\n","\n","end = time.time()\n","elapsed = end - start\n","print(\"Total Time:\", elapsed)"]},{"cell_type":"markdown","metadata":{},"source":["## Model Save"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save('V2_99.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"outputs":[],"source":["from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.applications.vgg19 import VGG19\n","from keras.applications.vgg19 import preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","import numpy as np\n","from glob import glob\n","import matplotlib.pyplot as plt\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{},"source":["## Accuracy Graph using limit to 350 epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# accuracies\n","plt.figure(figsize=(10,4))\n","plt.plot(history.history['accuracy'], label='train acc')\n","plt.plot(history.history['val_accuracy'], label='val acc')\n","plt.ylabel('Accuracy')\n","plt.xlabel('No. of Iteration')\n","plt.legend()\n","\n","# Set x-axis limit\n","plt.xlim(0, 350)\n","\n","plt.savefig('Accuracy')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Accuracy Graph "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["acc= history.history['accuracy']\n","val_acc= history.history['val_accuracy']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend(loc=0)\n","plt.figure()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Confution Matrix and Classification Report\n","!pip install mlxtend\n","from mlxtend.plotting import plot_confusion_matrix\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","import numpy as np\n","Y_pred = model.predict_generator(validation_generator,2304 //32+1)  #pred_prob\n","\n","y_pred = np.argmax(Y_pred, axis=1)#orig_test_labels1\n","print('Confusion Matrix')\n","print(confusion_matrix(validation_generator.classes, y_pred))\n","print('Classification Report')\n","target_names = ['Cherry_healthy', 'Cherry_mildew', 'Peach_healthy','Peach_spot','Soybean_Sudden_Death','Soybean_healthy','Strawberry_healthy','Strawberry_scorch','soybean_Yellow_Mosaic','soybean_bacterial_blight']\n","\n","print(classification_report(validation_generator.classes, y_pred, target_names=target_names  ))   #validation_generator.classes =orig_test_labels1\n","class_names = ['Cherry_healthy', 'Cherry_mildew', 'Peach_healthy','Peach_spot','Soybean_Sudden_Death','Soybean_healthy','Strawberry_healthy','Strawberry_scorch','soybean_Yellow_Mosaic','soybean_bacterial_blight']\n","mat= confusion_matrix(validation_generator.classes, y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["## Confusion Matrix "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import math\n","number_of_examples = len(validation_generator.filenames)\n","number_of_generator_calls = math.ceil(number_of_examples / (1.0 * 32)) \n","# 1.0 above is to skip integer division\n","\n","test_labels = []\n","test_images = []\n","\n","for i in range(0,int(number_of_generator_calls)):\n","    test_labels.extend(np.array(validation_generator[i][1]))\n","\n","for i in range(0,int(number_of_generator_calls)):\n","    test_images.extend(np.array(validation_generator[i][0]))\n","    %matplotlib inline\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","import matplotlib.pyplot as plt\n","predictions = model.predict_generator(validation_generator)\n","new_labels = []\n","for i in range(0,2304):\n","  new_labels.append(np.argmax(predictions[i]))\n","newtest_labels = []\n","for i in range(0,2304):\n","  newtest_labels.append(np.argmax(test_labels[i]))\n","cm = confusion_matrix(y_true=newtest_labels, y_pred=new_labels)"]},{"cell_type":"markdown","metadata":{},"source":["## Matthews Correlation Coefficient (MCC)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import matthews_corrcoef\n","\n","# Predict classes for validation data\n","Y_pred = model.predict_generator(validation_generator, 2304 // 32 + 1)\n","y_pred = np.argmax(Y_pred, axis=1)\n","\n","# True classes\n","y_true = validation_generator.classes\n","\n","# Calculate Matthews correlation coefficient\n","mcc = matthews_corrcoef(y_true, y_pred)\n","print(\"Matthews Correlation Coefficient:\", mcc)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(test_images)"]},{"cell_type":"markdown","metadata":{},"source":["## PR Curve train and validation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import precision_recall_curve\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","\n","# Compute precision and recall for each class\n","precision = dict()\n","recall = dict()\n","for i in range(len(room_types)):\n","    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_pred[:, i])\n","\n","# Create a plot with a larger font size\n","plt.figure(figsize=(8, 6))\n","\n","for i in range(len(room_types)):\n","    plt.plot(recall[i], precision[i], color=colors[i], lw=2, label='Class %s' % room_types[i])\n","\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","\n","# Increase font size for axis labels and title\n","plt.xlabel('Recall', fontsize=16)\n","plt.ylabel('Precision', fontsize=16)\n","plt.title('Precision-Recall Curve', fontsize=18)\n","\n","# Increase font size for legend\n","plt.legend(loc=\"lower left\", fontsize=14)\n","plt.savefig('PR_CNN-SVM',dpi=1200)\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## ROC Curve "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn import metrics\n","import matplotlib.pyplot as plt\n","from itertools import cycle\n","from scipy import interp\n","from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n","score = metrics.accuracy_score(newtest_labels, new_labels)\n","print(\"Accuracy score: {}\".format(score))\n","pred_prob = model.predict_generator(validation_generator)\n","\n","c = roc_auc_score(newtest_labels, pred_prob, multi_class='ovo')\n","print(\"AUC:\", c)\n","# Compute ROC curve and ROC area for each class\n","fpr = {}\n","tpr = {}\n","roc_auc = {}\n","thresh = {}\n","lw = 2\n","precision = {}\n","recall = {}\n","for i in range(10):  # here need to be modified \n","    fpr[i], tpr[i], thresh[i] = roc_curve(newtest_labels, pred_prob[:, i], pos_label=i)\n","    precision[i], recall[i], _ = roc_curve(newtest_labels, pred_prob[:, i], pos_label=i)\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n","\n","\n","\n","\n","plt.xlabel(\"recall\")\n","plt.ylabel(\"precision\")\n","plt.legend(loc=\"best\")\n","plt.title(\"precision vs. recall curve\")\n","plt.savefig('PR_CURVE')\n","plt.show()\n","\n","n_classes = 10\n","\n","# First aggregate all false positive rates\n","all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","\n","# Then interpolate all ROC curves at this points\n","mean_tpr = np.zeros_like(all_fpr)\n","for i in range(n_classes):\n","    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n","\n","# Finally average it and compute AUC\n","mean_tpr /= n_classes\n","\n","fpr[\"macro\"] = all_fpr\n","tpr[\"macro\"] = mean_tpr\n","roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","# Plot all ROC curves\n","plt.figure()\n","\n","colors = cycle(['red', 'orange', 'yellow', 'green', 'blue', 'purple', 'pink', 'brown', 'black', 'gray', 'white'])\n","for i, color in zip(range(n_classes), colors):\n","    plt.plot(fpr[i], tpr[i], color=color, lw=lw, label='ROC curve of class {0} (area = {1:0.4f})'\n","                                                       ''.format(i, roc_auc[i]))\n","\n","plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Some extension of Receiver operating characteristic to multi-class')\n","plt.legend(loc=\"lower right\")\n","plt.savefig('ROC')\n","plt.show()\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Grad CAM Code "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Display\n","from IPython.display import Image, display\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","\n","last_conv_layer_name = \"L4\"\n","img_path = \"/kaggle/input/four-plants-leaf-disease/Cherry_Strawberry_Peach_Soyabean/Validation/soybean_bacterial_blight/bb (34).bmp\"\n","\n","img_size = (120, 120)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_img_array(img_path, size):\n","    # `img` is a PIL image of size 299x299\n","    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n","    # `array` is a float32 Numpy array of shape (299, 299, 3)\n","    array = keras.preprocessing.image.img_to_array(img)\n","    # We add a dimension to transform our array into a \"batch\"\n","    # of size (1, 299, 299, 3)\n","    array = np.expand_dims(array, axis=0)\n","    return array\n","\n","\n","def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    # First, we create a model that maps the input image to the activations\n","    # of the last conv layer as well as the output predictions\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","\n","    # Then, we compute the gradient of the top predicted class for our input image\n","    # with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","\n","    # This is the gradient of the output neuron (top predicted or chosen)\n","    # with regard to the output feature map of the last conv layer\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","\n","    # This is a vector where each entry is the mean intensity of the gradient\n","    # over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    # We multiply each channel in the feature map array\n","    # by \"how important this channel is\" with regard to the top predicted class\n","    # then sum all the channels to obtain the heatmap class activation\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Prepare image\n","\n","img_array = preprocess_input(get_img_array(img_path, size=img_size))\n","model.layers[-1].activation = None\n","preds = model.predict(img_array)\n","\n","# Generate class activation heatmap\n","heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n","\n","# Display heatmap\n","plt.matshow(heatmap)\n","plt.savefig('Heatmap_soybean_bacterial_blight')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cam = plt.imread(img_path)\n","def save_and_display_gradcam(img_path, heatmap, cam_path=\"Superimposed_soybean_bacterial_blight.jpg\", alpha=0.4):\n","    # Load the original image\n","    img = keras.preprocessing.image.load_img(img_path)\n","    img = keras.preprocessing.image.img_to_array(img)\n","\n","    # Rescale heatmap to a range 0-255\n","    heatmap = np.uint8(255 * heatmap)\n","\n","    # Use jet colormap to colorize heatmap\n","    jet = cm.get_cmap(\"jet\")\n","\n","    # Use RGB values of the colormap\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","\n","    # Create an image with RGB colorized heatmap\n","    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n","    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n","\n","    # Superimpose the heatmap on original image\n","    superimposed_img = jet_heatmap * alpha + img\n","    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n","\n","    # Save the superimposed image\n","    superimposed_img.save(cam_path)\n","\n","    # Display Grad CAM\n","    display(Image(cam_path))\n","\n","\n","save_and_display_gradcam(img_path, heatmap)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import math\n","number_of_examples = len(validation_generator.filenames)\n","number_of_generator_calls = math.ceil(number_of_examples / (1.0 * 32)) \n","# 1.0 above is to skip integer division\n","\n","test_labels = []\n","test_images = []\n","\n","for i in range(0,int(number_of_generator_calls)):\n","    test_labels.extend(np.array(validation_generator[i][1]))\n","\n","for i in range(0,int(number_of_generator_calls)):\n","    test_images.extend(np.array(validation_generator[i][0]))\n","    %matplotlib inline\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","import matplotlib.pyplot as plt\n","predictions = model.predict_generator(validation_generator)\n","new_labels = []\n","for i in range(0,2304):\n","  new_labels.append(np.argmax(predictions[i]))\n","newtest_labels = []\n","for i in range(0,2304):\n","  newtest_labels.append(np.argmax(test_labels[i]))\n","cm = confusion_matrix(y_true=newtest_labels, y_pred=new_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plot_confusion_matrix(cm, classes,\n","                        normalize=False,\n","                        title='Confusion matrix',\n","                        cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting normalize=True.\n","    \"\"\"\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","            horizontalalignment=\"center\",\n","            color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    # plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","   "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cm_plot_labels =['Cherry_healthy', 'Cherry_mildew', 'Peach_healthy','Peach_spot','Soybean_Sudden_Death','Soybean_healthy','Strawberry_healthy','Strawberry_scorch','soybean_Yellow_Mosaic','soybean_bacterial_blight']\n","# cm_plot_labels = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13']\n","plot_confusion_matrix(cm=cm,classes=cm_plot_labels, title='Confusion Matrix'  )\n","plt.savefig('ConfusionMatrix')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3992404,"sourceId":6951266,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
